{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exploreCSR-ML-example_03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0POvE7A8P-5"
      },
      "source": [
        "# **Example 03**\n",
        "In this example, we will construct a **convolutional neural network** to improve our recogniztion of handwritten digits.\n",
        "\n",
        "First, we import the `TensorFlow` and `numpy` libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz7BF5Fm8NAI"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBDFUgYef5dK"
      },
      "source": [
        "Next, we load the MNIST dataset. Remember that this dataset has images of handwritten digits (from 0 to 9) and is divided into a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXZNvGSrIZsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f204d02-1a2b-4388-f00e-6599b4905716"
      },
      "source": [
        "data = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = data.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLOaRx0HgHOz"
      },
      "source": [
        "The input of the convolutional neural network must be a 4D array, so the first step is to **reshape** the data. If we don't do this, we will get an error when training the neural network. We also normalize the data, as we did in the previous example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv1JkKW4KU1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfb7fa4-353e-4fa2-df5d-1104d39d6bcd"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYp_P_guhmJI"
      },
      "source": [
        "Next, we design our convolutional neural network.\n",
        "\n",
        "First, we have a **convolutional** layer. We specify the number of convolutions (e.g., `32`), the size of the convolution (e.g., `3x3`), the activation function (e.g., `relu`), and the shape of the input data.\n",
        "\n",
        "We follow this with a **pooling** layer. This layer reduces the size of the image, while maintaining the content of the features highlighted by the convolution. We specify the type of pooling (e.g., max pooling) and the size of the pooling window (e.g., `2x2`). \n",
        "\n",
        "We then have a Flatten layer and a sequence of Dense layers, like in the previous example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5rHifKiKjDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e334a0e5-90ca-473f-d4a7-d054071ad6b2"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), # convolutional layer\n",
        "  tf.keras.layers.MaxPooling2D(2, 2), # pooling layer\n",
        "  tf.keras.layers.Flatten(), # flatten layer\n",
        "  tf.keras.layers.Dense(64, activation='relu'), # dense layer\n",
        "  tf.keras.layers.Dense(10, activation='softmax') # output layer\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                346176    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347,146\n",
            "Trainable params: 347,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwkzlPHd9vxM"
      },
      "source": [
        "We compile our convolutional neural network by specifying the loss function, the optimization algorithm, and the evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzm3oDeJKppP"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiZaiqe99lo"
      },
      "source": [
        "We then train our convolutional neural network to fit the data. Notice that it will take longer to train, since it's more complex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SphkGHtKsbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b6d155-7fad-47ac-caec-3c75dbe64185"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 33s 17ms/step - loss: 0.1660 - accuracy: 0.9507\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0598 - accuracy: 0.9816\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0401 - accuracy: 0.9875\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0302 - accuracy: 0.9910\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0218 - accuracy: 0.9930\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1088d49790>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvEHLP9EdGZX"
      },
      "source": [
        "Finally, we evaluate the performance of our convolutional neural network on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAlwkxSplS3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8971e2-dbf8-4cdb-89de-f22ff690ab3e"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0383 - accuracy: 0.9870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03833775594830513, 0.9869999885559082]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpJ6yOdEdcXT"
      },
      "source": [
        "The accuracy should now be around 99% on the training set and around 98% on the test set, so there is an improvement after adding the convolutions. **You can try to improve the accuracy further by adding more layers, neurons, or epochs, but be careful not to overfit the model!**\n",
        "\n",
        "Finally, we can understand convolutions better by visualizing the result of running the convolutions and pooling on each image. Notice that the convolutions are highlighting specific features in the images. **Try changing the value of `i` and `j` to visualize the result of other convolutions in other images.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlP8ni6qnUQN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "2a964760-9b84-49cc-b6e5-366469c91ff1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models\n",
        "i = 4 # convolution number (1 to 32)\n",
        "j = 2 # image number\n",
        "f, arr = plt.subplots(1, 3)\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "arr[0].imshow(x_test[j].reshape(28, 28)) # visualize original image\n",
        "arr[0].grid(False)\n",
        "for x in range(1, 3):\n",
        "  f = activation_model.predict(x_test[j].reshape(1, 28, 28, 1))[x-1] # visualize convolutions/pooling\n",
        "  arr[x].imshow(f[0, : , :, i])\n",
        "  arr[x].grid(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}